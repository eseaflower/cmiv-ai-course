{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning and Medical Imaging - Radiology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "We want to classify an image (patch) from an MR scan into one of 2 categories, {non-tumor,tumor}. Given such a classifier we could run it over all the image patches in an image to get a segmentation mask.\n",
    "\n",
    "To do this we frame the problem as trying to estimate the conditional probabillity of the class given the image pixels, $f(x)=p(y|x)$, where $f(x)$ is the function we are trying to learn. For $f(x)$ to be a valid probabillity distribution we only require that $f_{i}(x)\\ge 0$ and that $\\sum_{i=0}^n f_{i} = 1$. A common trick in machine learning to convert any function into a probabillity distribution is to define $g_{i}(x) = \\frac{e^{x_{i}}}{\\sum_{j=0}^n e^{x_{j}}}$, $g$ is called the softmax function. By applying the softmax to a vector valued function we end up with a valid probabillity distribution.\n",
    "We will use this to learn an \"unconstrained\" real valued function and apply a softmax to convert the output into a probabillity distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the below lines to download and unpack the data when running in Colab\n",
    "!wget -O data.tar https://github.com/eseaflower/cmiv-ai-course/raw/master/data.tar\n",
    "!tar -xvf data.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Dropout, Dense, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_device():\n",
    "    device_string = '/cpu:0'\n",
    "    gpu=0 # Set to None to avoid using the GPU\n",
    "    if gpu is not None:\n",
    "        device_string='/device:GPU:{0}'.format(gpu)\n",
    "    return tf.device(device_string)\n",
    "\n",
    "#def _init_keras():\n",
    "    # Setup the session to dynamically allocate memory\n",
    "#    config = tf.ConfigProto()\n",
    "#    config.gpu_options.allow_growth = True\n",
    "#    session = tf.Session(config=config)\n",
    "#    K.set_session(session)\n",
    "\n",
    "# Init the default session to be used by Keras\n",
    "#_init_keras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data():\n",
    "    rootdir = os.path.abspath(os.getcwd())\n",
    "    datadir = os.path.join(os.path.join(rootdir, \"data\"), \"MR\")\n",
    "    pos_pattern = os.path.join(os.path.join(datadir,\"positive_images\"), \"*.jpg\")\n",
    "    neg_pattern = os.path.join(os.path.join(datadir,\"negative_images\"), \"*.jpg\")\n",
    "    pos_filenames = list(glob.glob(pos_pattern))\n",
    "    neg_filenames = list(glob.glob(neg_pattern))\n",
    "\n",
    "    pos_images = [matplotlib.image.imread(fname) for fname in pos_filenames]\n",
    "    neg_images = [matplotlib.image.imread(fname) for fname in neg_filenames]\n",
    "    X = np.vstack([np.array(pos_images, dtype=np.float32), np.array(neg_images, dtype=np.float32)])\n",
    "    y = np.array([1]*len(pos_images) + [0]*len(neg_images), dtype=np.int32)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will download data and cache it.\n",
    "(X_train_orig, y_train_orig), (X_test_orig, y_test_orig) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the training and test sets, aswell as the dimension of each array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_orig.shape, y_train_orig.shape, X_test_orig.shape, y_test_orig.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the image patches by plotting some of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patches(X, y, y_true=None, to_plot=None):    \n",
    "    to_plot = to_plot or len(X)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    for i in range(to_plot):\n",
    "        plt.subplot(1, to_plot, i+1)\n",
    "        plt.imshow(X[i].reshape((32, 32)), interpolation='nearest', cmap='gray')\n",
    "        plt.text(0, 0, y[i], color='black', \n",
    "                 bbox=dict(facecolor='white', alpha=1))\n",
    "        if y_true is not None:\n",
    "            plt.text(0, 32, y_true[i], color='black', \n",
    "                     bbox=dict(facecolor='white', alpha=1))\n",
    "            \n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_patches(X_train_orig, y_train_orig, to_plot=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*First we need to run some code for support, you do not need to understand it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Dropout, Dense, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.image\n",
    "\n",
    "def get_device():\n",
    "    device_string = '/cpu:0'\n",
    "    gpu=0 # Set to None to avoid using the GPU\n",
    "    if gpu is not None:\n",
    "        device_string='/device:GPU:{0}'.format(gpu)\n",
    "    return tf.device(device_string)\n",
    "\n",
    "def load_data():\n",
    "    rootdir = os.path.abspath(os.getcwd())\n",
    "    datadir = os.path.join(os.path.join(rootdir, \"data\"), \"MR\")\n",
    "    pos_pattern = os.path.join(os.path.join(datadir,\"positive_images\"), \"*.jpg\")\n",
    "    neg_pattern = os.path.join(os.path.join(datadir,\"negative_images\"), \"*.jpg\")\n",
    "    pos_filenames = list(glob.glob(pos_pattern))\n",
    "    neg_filenames = list(glob.glob(neg_pattern))\n",
    "\n",
    "    pos_images = [matplotlib.image.imread(fname) for fname in pos_filenames]\n",
    "    neg_images = [matplotlib.image.imread(fname) for fname in neg_filenames]\n",
    "    X = np.vstack([np.array(pos_images, dtype=np.float32), np.array(neg_images, dtype=np.float32)])\n",
    "    y = np.array([1]*len(pos_images) + [0]*len(neg_images), dtype=np.int32)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "def crossentropy_logits(y_true, y_pred):\n",
    "    return K.categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "\n",
    "def to_tensors(X, y):\n",
    "    return X[:, :, :, np.newaxis], to_categorical(y, num_classes=2)\n",
    "\n",
    "def plot_patches(X, y, y_true=None, to_plot=None):    \n",
    "    to_plot = to_plot or len(X)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    for i in range(to_plot):\n",
    "        plt.subplot(1, to_plot, i+1)\n",
    "        plt.imshow(X[i].reshape((32, 32)), interpolation='nearest', cmap='gray')\n",
    "        plt.text(0, 0, y[i], color='black', \n",
    "                 bbox=dict(facecolor='white', alpha=1))\n",
    "        if y_true is not None:\n",
    "            plt.text(0, 32, y_true[i], color='black', \n",
    "                     bbox=dict(facecolor='white', alpha=1))\n",
    "            \n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "class LogCallback(Callback):            \n",
    "    def on_epoch_end(self, epoch, logs=None):                                        \n",
    "        print(\"{}: L: {:.7} A: {:.7} VL: {:.7} VA: {:.7}\".format(epoch,                                                                            \n",
    "                                                                 logs['loss'], \n",
    "                                                                 logs['accuracy'], \n",
    "                                                                 logs['val_loss'], \n",
    "                                                                 logs['val_accuracy']))\n",
    "        \n",
    "def Conv(n):\n",
    "    return Conv2D(n, (3, 3), padding=\"same\", activation='relu')\n",
    "\n",
    "def ConvMax(n):\n",
    "    return lambda x: MaxPooling2D(pool_size=(2, 2))(Conv(n)(x))\n",
    "\n",
    "real_dense = Dense\n",
    "def Dense(n):\n",
    "    return real_dense(n, activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model we need to:\n",
    "- Create the model\n",
    "- Decide on a loss function\n",
    "- Iteratively optimize the loss with respect to the model parameters\n",
    "- (Visualize the training and result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, optimizer, epochs):\n",
    "\n",
    "    (X_train_orig, y_train_orig), (X_test_orig, y_test_orig) = load_data()\n",
    "    plot_patches(X_train_orig, y_train_orig, to_plot=10)\n",
    "\n",
    "    X_train, y_train = to_tensors(X_train_orig, y_train_orig)\n",
    "    X_test, y_test = to_tensors(X_test_orig, y_test_orig)\n",
    "\n",
    "    with get_device():\n",
    "        model.compile(optimizer=optimizer, loss = crossentropy_logits, metrics=['accuracy'])\n",
    "\n",
    "        n_train = -1\n",
    "        logs = model.fit(X_train[:n_train], y_train[:n_train], \n",
    "                        validation_split=0.3, \n",
    "                        epochs=epochs,\n",
    "                        verbose=0,\n",
    "                        callbacks=[LogCallback()])\n",
    "    plt.plot(logs.history['accuracy'], c='r', label='Train')\n",
    "    plt.plot(logs.history['val_accuracy'], c='g', label='Validation')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    with get_device():\n",
    "        # Predict on test data\n",
    "        y_proba_test = model.predict(X_test)\n",
    "    y_pred_test = np.argmax(y_proba_test, axis=-1)\n",
    "    y_true = np.argmax(y_test, axis=-1)\n",
    "    errors = y_pred_test != y_true\n",
    "    # Compute the accuracy    \n",
    "    print(\"Accuracy: {}\".format(1.0-np.mean(errors)))\n",
    "\n",
    "    # Plot the first examples.\n",
    "    to_evaluate = 15\n",
    "    X_eval = X_test[:to_evaluate]    \n",
    "    y_eval = y_pred_test[:to_evaluate]\n",
    "    plot_patches(X_eval, y_eval, y_true=y_true[:to_evaluate])\n",
    "\n",
    "    # Plot the first error examples\n",
    "    X_eval = X_test[np.where(errors)][:to_evaluate]\n",
    "    y_eval = y_pred_test[np.where(errors)][:to_evaluate]\n",
    "    plot_patches(X_eval, y_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "\n",
    "When dealing with images we often use a hypothesis of stationarity in the image, pixels in a neighbourhood are correlated simliarilly across the entire image, the absolute coordinate (x,y) of a pixel does not influence its distribution. Using this hypothesis we can share weights across the image, thus reducing the total nbumber of parameters that need to be learned. This is the idea behind Convolutional Neural Networks.\n",
    "\n",
    "In CNNs the parameters of the model is convolved across the image to produce feature maps. The feature maps produced in one layer can be used as input to another convolution layer in the same way as layers are stacked in a feed-forward network. To introduce some translation invariance into the model the output feature maps are pooled at certain stages. This effectively increases the receptive field of later convolutions, allowing them to \"see\" a larger part of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the input to output relationship that is our neural network.\n",
    "\n",
    "We need to decide:\n",
    "- Input/output data dimensions\n",
    "- Number of hidden layers\n",
    "- Number of neurons in each layer\n",
    "- Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(cnn_backbone, mlp_top=[]):\n",
    "    # Images are 1 channel and 32x32\n",
    "    input = Input(shape=(32, 32, 1))\n",
    "    x = input\n",
    "    for layer in cnn_backbone:\n",
    "        x = layer(x)\n",
    "    x = Flatten()(x)\n",
    "    for layer in mlp_top:\n",
    "        x = layer(x)\n",
    "    x = real_dense(2)(x)\n",
    "    return Model(input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "We can experiment with a number of parameters for our learning problem:\n",
    "\n",
    "Architecture:\n",
    "- Change the number of hidden nodes `Conv(64)`\n",
    "- Change the number of layers `[Conv(32), Conv(64)]`\n",
    "- Add downsampling `[ConvMax(32), ConvMax(64)]` - `ConvMax` adds both a `Conv` and `MaxPool` layer.\n",
    "- Add normalization `[ConvMax(32), Dropout(0.2), ConvMax(64)]`\n",
    "- (*Extra*) - Add a MLP classifier at the end `[Dropout(0.2), Dense(256)]`\n",
    "\n",
    "Optimizer:\n",
    "- We can try another optimizer `optimizer = Adam()`\n",
    "\n",
    "Time:\n",
    "- We can increase the number of steps the optimizer takes (how far we run) `epochs=30`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_cnn_model([Conv(32)])\n",
    "#model = build_cnn_model([Conv(32), Conv(64)])\n",
    "#model = build_cnn_model([ConvMax(32), ConvMax(64)], [Dropout(0.2), Dense(256)])\n",
    "\n",
    "optimizer = SGD()\n",
    "#optimizer = Adam()\n",
    "\n",
    "epochs = 5\n",
    "#epochs = 30\n",
    "\n",
    "# Run the experiment with the above specified model and parameters.\n",
    "run_experiment(model, optimizer, epochs)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
