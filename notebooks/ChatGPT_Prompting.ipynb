{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/k-stacke/cmiv-ai-course/blob/master/ChatGPT_Prompting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promting with ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "How can we use Large Language Models (ChatGPT in specific) to solve text-based problems such as text summarization and data mining from unstructured text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade openai\n",
    "\n",
    "import os\n",
    "import io\n",
    "import requests\n",
    "import openai\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: update to other info once we have a token specific for the AI course\n",
    "\n",
    "response = requests.get('CHANGE ME')\n",
    "config = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTezC7cN_F_k"
   },
   "outputs": [],
   "source": [
    "# Set up the clinent to access the OpenAI API\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=config['OPENAI_API_VERSION'],\n",
    "    azure_endpoint=config['AZURE_OPENAI_ENDPOINT'],\n",
    "    api_key=config['AZURE_OPENAI_API_KEY'])\n",
    "\n",
    "CHATGPT_ENGINE_NAME = config['engine_name-chatgpt']\n",
    "print(\"Using engine name\", CHATGPT_ENGINE_NAME, \"and API version\", openai.api_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for calling the model\n",
    "def get_completion(prompt, model=CHATGPT_ENGINE_NAME, temperature=0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence. \n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Write the following using only emoticons.\n",
    "\n",
    "'''Nu ska vi prata ChatGPT. Det blir roligt. Men oroa er inte, snart Ã¤r det kaffe!'\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" CT -  CT ABDOMEN AND PELVIS ENHANCED -  24-Feb-2020, 12:45 PM\n",
    "&nbsp;  \n",
    "&nbsp;  \n",
    "INDICATION:  Rule out diverticulitis   .&nbsp;  \n",
    "&nbsp;  \n",
    "TECHNIQUE: Volumetric image acquisition of the       abdomen and pelvis    with   intravenous   contrast.  Coronal  and sagittal  reformats were performed post-acquisition.&nbsp;  \n",
    "&nbsp;  \n",
    "COMPARISON:  CT renal colic study from 10/04/16 &nbsp;  \n",
    "&nbsp;  \n",
    "FINDINGS:&nbsp;  \n",
    "&nbsp;  \n",
    "    There are a few scattered hypoattenuating lesions in the liver likely representing cysts. Cysts were described on the prior CT examination. The&nbsp;  \n",
    "&nbsp;  \n",
    "There is no evidence for colonic diverticulosis or colitis. The appendix is identified and is normal.&nbsp;  \n",
    "&nbsp;  \n",
    "There is a trace amount of pelvic free fluid identified. There is mild hazy stranding in the left adnexal region which may be inflammatory. A definite adnexal mass or cyst is not seen but a recently ruptured cyst could potentially demonstrate this finding. Please note the gynecologic structures are not optimally assessed by CT. &nbsp;  \n",
    "&nbsp;  \n",
    "The    remainder of the    intra-abdominal structures show no gross   abnormality   .Lung bases are grossly clear. &nbsp;  \n",
    "&nbsp;  \n",
    "No aggressive bony abnormality is identified.&nbsp;  \n",
    "&nbsp;  \n",
    "OPINION: &nbsp;  \n",
    "&nbsp;  \n",
    "   No evidence for diverticulosis/diverticulitis/colitis. Appendix is normal.&nbsp;  \n",
    "&nbsp;  \n",
    "Mild inflammatory change in the left adnexal region which may be secondary to recent ruptured cyst. Ultrasound follow-up could be performed. &nbsp;  \n",
    "&nbsp;  \n",
    "If you have received this report in error, please return by Fax to Health Information Management at Trillium Health Partners at 905-848-7677. If you don't have access to fax, or have other questions, please call 905-848-7580 ext. 2172.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Format the text below:  \n",
    " {text}\n",
    " \"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Explain the report below to me as if I where 10 years old\"\n",
    "\n",
    "prompt = f\"\"\"{instruction}: \n",
    " {text}\n",
    " \"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Try and change the style of the explaination. Some example prompts to get the imagination going:\n",
    "+ `Explain the report below to me as if I was the patient/a high school student/75 years old`\n",
    "+ `Explain the report below to me giving the most inportant parts as a bullent point list`\n",
    "+ `Explain the report below to me by first defining all medical terms in a list, then give a short summarization of the conclusions with 1-3 sentences.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract structured information from unstructured report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large language models (LLMs) are good at extracting information from unstructured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"Extract information about all nodules found in a JSON fomat with the categories size and location. \n",
    "Change metric values to imperial.\n",
    "If no nodules are found, return empty list.\"\"\"\n",
    "\n",
    "text = \"This is an example radiologist report. One nodule found, 2.5x2.5cm located in the lower-left part of the liver.\"\n",
    "\n",
    "prompt = f\"\"\"{instruction}: \n",
    " {text}\n",
    " \"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Extract information about all nodules found in a JSON fomat with the categories size and location. If no nodules are found, return empty brackets.\"\n",
    "\n",
    "text = \"This is an example radiologist report. Normal exam, no nodules found. The nodule found in the previous exam (of size 2.5cmx2.5cm) is not visible.\"\n",
    "\n",
    "prompt = f\"\"\"{instruction}: \n",
    " {text}\n",
    " \"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Play around with the instruction and the text. \n",
    "1. Keep the prompt constant and change the text. How does it behave? When does it fail? What type of information does/cab it extract?\n",
    "2. Keep the text constant and change the prompt. Can you fix so that it outputs what you want? Can you get it to answer in another language? Can you improve the quality of the output by adding more/clearer instructions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beware of hallucinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT and other LLMs has a tendency to output so called hallucinations. It has no knowledge of what is true or false, and may therefore output answers to questions/tasks sounding confident but is actually incorrect or making things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Grade the nodule according to the Swedish Society of Radiology guidelines of liver nodules.\"\n",
    "\n",
    "text = \"\"\"This is an example radiologist report. One nodule found, 2.5x2.5cm located in the lower-left part of the liver.\"\"\"\n",
    "\n",
    "\n",
    "prompt = f\"\"\"{instruction}: \n",
    " {text}\n",
    " \"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Play with the text and prompt and see if you can get the model to output inconsistensies or incorrect information. See if you can change the prompt to mitigate this behaviour. \n",
    "\n",
    "You can add reference text to the instructions and ask the model to only use these when solving the task."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyME5AJJ1Ta8MDdJ4Hnr8RGG",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
