{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k-stacke/cmiv-ai-course/blob/master/ChatGPT_Prompting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Promting with ChatGPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem\n",
        "\n",
        "We want to ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# NOTE: update to other info once we have a token specific for the AI course\n",
        "\n",
        "response = requests.get('CHANGE ME')\n",
        "env_vars = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env_vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTezC7cN_F_k"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import openai\n",
        "\n",
        "openai.api_type = env_vars[\"OPENAI_API_TYPE\"]\n",
        "openai.api_version = env_vars[\"OPENAI_API_VERSION\"]\n",
        "openai.api_base = env_vars[\"OPENAI_API_BASE\"]  # Your Azure OpenAI resource's endpoint value.\n",
        "openai.api_key = env_vars[\"OPENAI_API_KEY\"]\n",
        "openai.api_azure_engine = env_vars[\"OPENAI_API_AZURE_ENGINE\"]\n",
        "\n",
        "model_name = env_vars[\"engine_name-chatgpt\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=model_name, temperature=0):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        engine=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = f\"\"\"\n",
        "You should express what you want a model to do by \\ \n",
        "providing instructions that are as clear and \\ \n",
        "specific as you can possibly make them. \\ \n",
        "In many cases, longer prompts provide more clarity \\ \n",
        "and context for the model, which can lead to \\ \n",
        "more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks \\ \n",
        "into a single sentence. \n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"\"\" CT -  CT ABDOMEN AND PELVIS ENHANCED -  24-Feb-2020, 12:45 PM\n",
        "&nbsp;  \n",
        "&nbsp;  \n",
        "INDICATION:  Rule out diverticulitis   .&nbsp;  \n",
        "&nbsp;  \n",
        "TECHNIQUE: Volumetric image acquisition of the       abdomen and pelvis    with   intravenous   contrast.  Coronal  and sagittal  reformats were performed post-acquisition.&nbsp;  \n",
        "&nbsp;  \n",
        "COMPARISON:  CT renal colic study from 10/04/16 &nbsp;  \n",
        "&nbsp;  \n",
        "FINDINGS:&nbsp;  \n",
        "&nbsp;  \n",
        "    There are a few scattered hypoattenuating lesions in the liver likely representing cysts. Cysts were described on the prior CT examination. The&nbsp;  \n",
        "&nbsp;  \n",
        "There is no evidence for colonic diverticulosis or colitis. The appendix is identified and is normal.&nbsp;  \n",
        "&nbsp;  \n",
        "There is a trace amount of pelvic free fluid identified. There is mild hazy stranding in the left adnexal region which may be inflammatory. A definite adnexal mass or cyst is not seen but a recently ruptured cyst could potentially demonstrate this finding. Please note the gynecologic structures are not optimally assessed by CT. &nbsp;  \n",
        "&nbsp;  \n",
        "The    remainder of the    intra-abdominal structures show no gross   abnormality   .Lung bases are grossly clear. &nbsp;  \n",
        "&nbsp;  \n",
        "No aggressive bony abnormality is identified.&nbsp;  \n",
        "&nbsp;  \n",
        "OPINION: &nbsp;  \n",
        "&nbsp;  \n",
        "   No evidence for diverticulosis/diverticulitis/colitis. Appendix is normal.&nbsp;  \n",
        "&nbsp;  \n",
        "Mild inflammatory change in the left adnexal region which may be secondary to recent ruptured cyst. Ultrasound follow-up could be performed. &nbsp;  \n",
        "&nbsp;  \n",
        "If you have received this report in error, please return by Fax to Health Information Management at Trillium Health Partners at 905-848-7677. If you don't have access to fax, or have other questions, please call 905-848-7580 ext. 2172.\"\"\"\n",
        "prompt = f\"\"\"===== Format the text below:  \n",
        " {text}\n",
        " \"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = f\"\"\"===== Explain the report below to me as if I where 10 years old:  \n",
        " {text}\n",
        " \"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyME5AJJ1Ta8MDdJ4Hnr8RGG",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
