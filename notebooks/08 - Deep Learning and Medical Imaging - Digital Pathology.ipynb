{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6vYAeWDBCxw"
   },
   "source": [
    "# Deep Learning and Medical Imaging - Digital Pathology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HqfaN8OeBCxy"
   },
   "source": [
    "In this exercise, we will solve the same problem as before, i.e. we have images corresponding to 2 categories and we would like to train a classifier that can separate between the two sets of images. However, in this case we are looking at HE-stained digital pathology images (i.e. RGB images instead of grayscale images), where we will try to separate between epithelium and stroma regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KGbhPuILBCxz"
   },
   "source": [
    "## Imports, sampling and data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KCrVn5CCQo8"
   },
   "source": [
    "We start by downloading the data that we will use. \n",
    "\n",
    "The data is downloaded from http://www.andrewjanowczyk.com/deep-learning/. The datasets available on this webpage were published in conjunction with a tutorial on deep learning for digital pathology (http://www.jpathinformatics.org/text.asp?2016/7/1/29/186902). Feel free to check this out if you want to explore the topic of deep learning and digital pathology any further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BH4haP2RBCx0"
   },
   "outputs": [],
   "source": [
    "# Run the below lines to download and unpack the data when running in Colab.\n",
    "# Remember to uncomment.\n",
    "!wget -O epi.tar http://andrewjanowczyk.com/wp-static/epi.tgz\n",
    "!mkdir epi\n",
    "!tar -xf epi.tar -C epi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rmI6bpuLCsg4"
   },
   "source": [
    "This time, the data has not been sampled, hence we need to create the samples (image patches) ourselves. The original images are located in the folder \"epi\" and the masks for epithelium in the subfolder \"masks\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_xANPAcC3mS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "folder = \"epi\"\n",
    "\n",
    "# Find all images and mask images\n",
    "orig_images = glob.glob(os.path.join(folder,\"*.tif\"))\n",
    "mask_images = glob.glob(os.path.join(folder,\"masks\",\"*.png\"))\n",
    "\n",
    "# Not all images have mask images, so we need to find those that do\n",
    "orig_images_with_mask = list()\n",
    "orig_image_names = [os.path.splitext(os.path.basename(fname))[0] for fname in orig_images]\n",
    "mask_image_names = set([os.path.splitext(os.path.basename(fname))[0].replace(\"_mask\",\"\") for fname in mask_images])\n",
    "for orig_image in orig_images:\n",
    "    orig_image_name = os.path.splitext(os.path.basename(orig_image))[0]\n",
    "    if orig_image_name in mask_image_names:\n",
    "        mask_image = os.path.join(folder,\"masks\",orig_image_name + \"_mask.png\")\n",
    "        orig_images_with_mask.append((orig_image, mask_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tH8kZfw-Hpjs"
   },
   "source": [
    "Before we start sampling, let's have a look at the data so we understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pttX9boyHu_r"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, segmentation\n",
    "\n",
    "number_of_images_to_display = 3\n",
    "\n",
    "# For each original image with mask\n",
    "for (orig_image, mask_image) in orig_images_with_mask[0:number_of_images_to_display]:\n",
    "    print(\"Displaying:\", orig_image,\"and\",mask_image)\n",
    "    org_im = io.imread(orig_image)\n",
    "    mask_im = io.imread(mask_image)\n",
    "    mask_edges = segmentation.mark_boundaries(org_im, mask_im)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(mask_edges)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(mask_im, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fuR6Ph2KIwFM"
   },
   "source": [
    "Time to sample the data.\n",
    "\n",
    "In the code below, you can control the number of samples per images, and also the size of the samples. Note, if changing the size of the data, you need  to ensure that you update subsequent parts of the notebook that assumes the size of 64.\n",
    "\n",
    "In this exercise, we will also split the data into separate training and test sets right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YoqRt4AnO8PN"
   },
   "outputs": [],
   "source": [
    "# Simple function to sample an image\n",
    "def sample_and_save(image, pos, sample_size, folder, sample_counter):\n",
    "    for xy in pos:\n",
    "        sample_counter = sample_counter + 1\n",
    "        x = xy[0]\n",
    "        y = xy[1]\n",
    "        sample = image[x-sample_size//2:x+sample_size//2,\n",
    "                       y-sample_size//2:y+sample_size//2,\n",
    "                       :]\n",
    "        io.imsave(folder + str(sample_counter).zfill(5) + \".png\", sample)\n",
    "\n",
    "    return sample_counter  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQCEpMX4Ps3m"
   },
   "source": [
    "Run the cell below once only, as it might take considerable time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SyjiLIOFbVd"
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import erosion, square\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "# Parameters for sampling\n",
    "sample_size = 64\n",
    "samples_per_image = 10\n",
    "\n",
    "# Set and create folders for samples\n",
    "folder = \"epi\"\n",
    "output_folder = os.path.join(folder,\"samples\")\n",
    "if os.path.exists(output_folder):\n",
    "    shutil.rmtree(output_folder)\n",
    "os.mkdir(output_folder)\n",
    "for sample_category in [\"train\",\"test\"]:\n",
    "    os.mkdir(os.path.join(output_folder,sample_category))\n",
    "    os.mkdir(os.path.join(output_folder,sample_category,\"positive\"))\n",
    "    os.mkdir(os.path.join(output_folder,sample_category,\"negative\"))\n",
    "  \n",
    "# Shuffle our cases\n",
    "np.random.seed(123)\n",
    "np.random.shuffle(orig_images_with_mask)\n",
    "\n",
    "# Start sampling patches for training, but we'll change sample category \n",
    "# as we move along based upon our counter\n",
    "counter = 0\n",
    "sample_category = \"train\"\n",
    "# Set sample counters\n",
    "pos_sample_counter = 0\n",
    "neg_sample_counter = 0\n",
    "# For each original image with mask\n",
    "for (orig_image, mask_image) in orig_images_with_mask:\n",
    "    counter = counter + 1\n",
    "    \n",
    "    if counter == 35:\n",
    "        # Change to test\n",
    "        sample_category = \"test\"\n",
    "        # Reset sample counters\n",
    "        pos_sample_counter = 0\n",
    "        neg_sample_counter = 0\n",
    "    \n",
    "    print(\"Processing\", orig_image,\"and\",mask_image,\"to create\",sample_category)\n",
    "    org_im = io.imread(orig_image)\n",
    "    mask_im = io.imread(mask_image)\n",
    "    \n",
    "    # Create foreground and background masks\n",
    "    fg_im = np.zeros(mask_im.shape)\n",
    "    bg_im = np.zeros(mask_im.shape)\n",
    "    fg_im[mask_im == 255] = 1\n",
    "    bg_im[mask_im != 255] = 1\n",
    "    \n",
    "    # Erode masks\n",
    "    fg_im_eroded = erosion(fg_im, square(sample_size//2))\n",
    "    bg_im_eroded = erosion(bg_im, square(sample_size//2))\n",
    "    \n",
    "    # Remove masks close to the edges of images\n",
    "    im_size = org_im.shape[0]\n",
    "    fg_im_eroded[:sample_size//2,:] = 0\n",
    "    fg_im_eroded[im_size-sample_size//2:,:] = 0\n",
    "    fg_im_eroded[:,:sample_size//2] = 0\n",
    "    fg_im_eroded[:,im_size-sample_size//2:] = 0\n",
    "    bg_im_eroded[:sample_size//2,:] = 0\n",
    "    bg_im_eroded[im_size-sample_size//2:,:] = 0\n",
    "    bg_im_eroded[:,:sample_size//2] = 0\n",
    "    bg_im_eroded[:,im_size-sample_size//2:] = 0\n",
    "\n",
    "    # Find indices to sample from\n",
    "    pos_ind = np.where(fg_im_eroded==1)\n",
    "    pos_ind = np.concatenate((np.expand_dims(pos_ind[0], axis=1),\n",
    "                              np.expand_dims(pos_ind[1], axis=1)), axis=1)\n",
    "    neg_ind = np.where(bg_im_eroded==1)\n",
    "    neg_ind = np.concatenate((np.expand_dims(neg_ind[0], axis=1),\n",
    "                              np.expand_dims(neg_ind[1], axis=1)), axis=1)\n",
    "    \n",
    "    # Shuffle indices\n",
    "    np.random.seed(123)\n",
    "    np.random.shuffle(pos_ind)\n",
    "    np.random.seed(321)\n",
    "    np.random.shuffle(neg_ind)\n",
    "\n",
    "    # Get indices to use\n",
    "    pos_ind = pos_ind[0:samples_per_image+1,:]\n",
    "    neg_ind = neg_ind[0:samples_per_image+1,:]\n",
    "\n",
    "    # Sample the images\n",
    "    pos_sample_counter = sample_and_save(org_im, pos_ind, sample_size, \n",
    "                                         os.path.join(output_folder, sample_category, \"positive\", \"pos_\"), \n",
    "                                         pos_sample_counter)\n",
    "    neg_sample_counter = sample_and_save(org_im, neg_ind, sample_size, \n",
    "                                         os.path.join(output_folder, sample_category, \"negative\", \"neg_\"), \n",
    "                                         neg_sample_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UCnqU0BAPgtu"
   },
   "source": [
    "No need to worry about the warnings that are produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OuZJwAgNJPGJ"
   },
   "source": [
    "We list the samples we have available and split them into train, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-m_D2miBCx4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(datadir, sample_category, apply_train_test_split=True):\n",
    "    pos_filenames = glob.glob(os.path.join(datadir,sample_category,\"positive\", \"*.png\"))\n",
    "    neg_filenames = glob.glob(os.path.join(datadir,sample_category,\"negative\", \"*.png\"))\n",
    "    \n",
    "    pos_images = [matplotlib.image.imread(fname) for fname in pos_filenames]\n",
    "    neg_images = [matplotlib.image.imread(fname) for fname in neg_filenames]\n",
    "    \n",
    "    X = np.vstack([np.array(pos_images, dtype=np.float32), np.array(neg_images, dtype=np.float32)])\n",
    "    y = np.array([1]*len(pos_images) + [0]*len(neg_images), dtype=np.int32)\n",
    "    \n",
    "    if apply_train_test_split:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=0.2, \n",
    "                                                            stratify=y,\n",
    "                                                            random_state=123)\n",
    "    \n",
    "        return (X_train, y_train), (X_test, y_test)\n",
    "    else:\n",
    "        p = np.random.permutation(len(X))\n",
    "        return (X[p], y[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jDeOaAwBCx6"
   },
   "outputs": [],
   "source": [
    "# This will load data from disk and cache it.\n",
    "(X_train, y_train), (X_val, y_val) = load_data(\"epi/samples\", \"train\")\n",
    "(X_test, y_test) = load_data(\"epi/samples\", \"test\", apply_train_test_split=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M9Jj8fKiBCx8"
   },
   "source": [
    "Check the size of the training and test sets, as well as the dimension of each array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRxtQanzBCx-"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mcvOQa5GJ5Cn",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "____\n",
    "## Exercise\n",
    "Can you spot the difference in the shape (size) of the data as compared to the previous exercise?\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WuG1UyZOBCyA"
   },
   "source": [
    "We can visualize the image patches by plotting some of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JYzugdUBCyB"
   },
   "outputs": [],
   "source": [
    "def plot_patches(X, y, y_true=None, to_plot=None):    \n",
    "    to_plot = to_plot or len(X)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    for i in range(to_plot):\n",
    "        plt.subplot(1, to_plot, i+1)\n",
    "        plt.imshow(X[i].reshape((64, 64, 3)), interpolation='nearest')\n",
    "        plt.text(0, 0, y[i], color='black', \n",
    "                 bbox=dict(facecolor='white', alpha=1))\n",
    "        if y_true is not None:\n",
    "            plt.text(0, 32, y_true[i], color='black', \n",
    "                     bbox=dict(facecolor='white', alpha=1))\n",
    "            \n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PHbvNYZaBCyD"
   },
   "outputs": [],
   "source": [
    "print(\"Training samples\")\n",
    "plot_patches(X_train, y_train, to_plot=10)\n",
    "print(\"Validation samples\")\n",
    "plot_patches(X_val, y_val, to_plot=10)\n",
    "print(\"Test samples\")\n",
    "plot_patches(X_test, y_test, to_plot=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrAfCoxqRXik"
   },
   "source": [
    "To get started, we will use exactly the same approach as last time, but adjusted for somewhat large image patches and the fact that they are RGB images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hY27HZaTp-uy",
    "tags": []
   },
   "source": [
    "## Import of libraries for deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfpuZNCUqEjC"
   },
   "source": [
    "As before, we need to setup some libraries to use for deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CTsGHLYMqFaH"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, BatchNormalization, Dropout, Dense, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_device():\n",
    "    device_string = '/cpu:0'\n",
    "    # Set to None to avoid using a GPU\n",
    "    gpu=0\n",
    "    if gpu is not None:\n",
    "        device_string='/device:GPU:{0}'.format(gpu)\n",
    "    return tf.device(device_string)\n",
    "\n",
    "# def _init_keras():\n",
    "#     # Setup the session to dynamically allocate memory\n",
    "#     config = tf.ConfigProto()\n",
    "#     config.gpu_options.allow_growth = True\n",
    "#     session = tf.Session(config=config)\n",
    "#     K.set_session(session)\n",
    "\n",
    "# Init the default session to be used by Keras\n",
    "# _init_keras()\n",
    "\n",
    "# Set logging level to error to avoid some output\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kMGs3aE4sLx2"
   },
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def to_tensors(X, y):\n",
    "    return X[:, :, :, :], to_categorical(y, num_classes=2)\n",
    "\n",
    "class LogCallback(Callback):            \n",
    "    def on_epoch_end(self, epoch, logs=None):                                        \n",
    "        print(\"{}: L: {:.7} A: {:.7} VL: {:.7} VA: {:.7}\".format(epoch,                                                                            \n",
    "                                                                 logs['loss'], \n",
    "                                                                 logs['accuracy'], \n",
    "                                                                 logs['val_loss'], \n",
    "                                                                 logs['val_accuracy'])) \n",
    "\n",
    "def crossentropy_logits(y_true, y_pred):\n",
    "    return K.categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "  \n",
    "def to_tensors(X, y):\n",
    "    # Convert X into a 4D tensor and y into a 2D tensor with 1-hot encoding\n",
    "    return X[:, :, :, :], to_categorical(y, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "raKDuK4SBCyF",
    "tags": []
   },
   "source": [
    "## MLP\n",
    "\n",
    "We start off with an MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QixFbZ3RmA6"
   },
   "outputs": [],
   "source": [
    "# Define MLP model to use\n",
    "def build_mlp_model():\n",
    "    # Images are 3 channel and 64x64\n",
    "    input = Input(shape=(64, 64, 3))\n",
    "    x = Flatten()(input)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(512, activation='relu')(x)    \n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(512, activation='relu')(x)    \n",
    "    x = Dense(2)(x)\n",
    "    return Model(input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eIN9fHDotG4s"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "(X_train, y_train), (X_val, y_val) = load_data(\"epi/samples\", \"train\")\n",
    "(X_test, y_test) = load_data(\"epi/samples\", \"test\", apply_train_test_split=False)\n",
    "\n",
    "# Plot example data\n",
    "print(\"Example patches of epithelium and stroma\")\n",
    "plot_patches(X_train, y_train, to_plot=10)\n",
    "\n",
    "# Convert to expected format\n",
    "X_train, y_train = to_tensors(X_train, y_train)\n",
    "X_val, y_val = to_tensors(X_val, y_val)\n",
    "X_test, y_test = to_tensors(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DyXOkI-OQsKO"
   },
   "outputs": [],
   "source": [
    "# Run training\n",
    "with get_device():\n",
    "    model = build_mlp_model()\n",
    "\n",
    "    optimizer = SGD(lr=0.003)\n",
    "    model.compile(optimizer=optimizer, loss = crossentropy_logits, metrics=['accuracy'])\n",
    "\n",
    "    n_train = -1\n",
    "    logs = model.fit(X_train[:n_train], y_train[:n_train], \n",
    "                     validation_data=(X_val, y_val), \n",
    "                     epochs=25,\n",
    "                     verbose=0, callbacks=[LogCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92FGZRNJtMVU"
   },
   "outputs": [],
   "source": [
    "# Display training curves    \n",
    "plt.plot(logs.history['accuracy'])\n",
    "plt.plot(logs.history['val_accuracy'])\n",
    "plt.show()\n",
    "\n",
    "# Predict on test data\n",
    "y_proba_test = model.predict(X_test)\n",
    "y_pred_test = np.argmax(y_proba_test, axis=-1)\n",
    "y_true = np.argmax(y_test, axis=-1)\n",
    "errors = y_pred_test != y_true\n",
    "\n",
    "# Compute the accuracy    \n",
    "print(\"Accuracy: {}\".format(1.0-np.mean(errors)))\n",
    "\n",
    "# Plot the first examples\n",
    "print(\"Some predicted examples\")\n",
    "to_evaluate = 15\n",
    "X_eval = X_test[:to_evaluate]    \n",
    "y_eval = y_pred_test[:to_evaluate]\n",
    "plot_patches(X_eval, y_eval, y_true=y_true[:to_evaluate])\n",
    "\n",
    "# Plot the first error examples\n",
    "print(\"Some false predictions\")\n",
    "X_eval = X_test[np.where(errors)][:to_evaluate]\n",
    "y_eval = y_pred_test[np.where(errors)][:to_evaluate]\n",
    "plot_patches(X_eval, y_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q2gp9lmfBCyt"
   },
   "source": [
    "## CNN\n",
    "\n",
    "That didn't work very well. Let's try our CNNs instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CmjucGnbBCy7"
   },
   "outputs": [],
   "source": [
    "# Define CNN model to use\n",
    "def build_conv_model():\n",
    "    # Images are 3 channel and 64x64\n",
    "    input = Input(shape=(64, 64, 3))\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(input)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(2)(x)\n",
    "    return Model(input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CmjucGnbBCy8"
   },
   "outputs": [],
   "source": [
    "# Run training\n",
    "with get_device():\n",
    "    model = build_conv_model()\n",
    "\n",
    "    optimizer = Adam()\n",
    "    model.compile(optimizer=optimizer, loss = crossentropy_logits, metrics=['accuracy'])\n",
    "\n",
    "    n_train = -1\n",
    "    logs = model.fit(X_train[:n_train], y_train[:n_train], \n",
    "                     validation_data=(X_val, y_val), \n",
    "                     epochs=25,\n",
    "                     verbose=0,\n",
    "                     callbacks=[LogCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8aY1Q61taih"
   },
   "outputs": [],
   "source": [
    "# Display training curves \n",
    "plt.plot(logs.history['accuracy'])\n",
    "plt.plot(logs.history['val_accuracy'])\n",
    "plt.show()\n",
    "\n",
    "# Predict on test data\n",
    "with get_device():\n",
    "    y_proba_test = model.predict(X_test)\n",
    "\n",
    "y_pred_test = np.argmax(y_proba_test, axis=-1)\n",
    "y_true = np.argmax(y_test, axis=-1)\n",
    "errors = y_pred_test != y_true\n",
    "\n",
    "# Compute the accuracy    \n",
    "print(\"Test accuracy: {}\".format(1.0-np.mean(errors)))\n",
    "\n",
    "# Plot the first examples\n",
    "print(\"Some predicted examples\")\n",
    "to_evaluate = 15\n",
    "X_eval = X_test[:to_evaluate]    \n",
    "y_eval = y_pred_test[:to_evaluate]\n",
    "plot_patches(X_eval, y_eval, y_true=y_true[:to_evaluate])\n",
    "\n",
    "# Plot the first error examples\n",
    "print(\"Some false predictions\")\n",
    "X_eval = X_test[np.where(errors)][:to_evaluate]\n",
    "y_eval = y_pred_test[np.where(errors)][:to_evaluate]\n",
    "plot_patches(X_eval, y_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wendFbNEh-x"
   },
   "source": [
    "As we can note in this exercise, we don't have that many images to sample from, only about 40 images. Also, we haven't sampled our data that densely, i.e. just a few samples from each image. This means that we just have a few image samples to train on and with a limited variation. \n",
    "\n",
    "The natural approach to handle this would of course be to collect more images, annotate them and/or to sample more densely from the images that are available. Sometimes (often) this is not possible, and instead we need to use other techniques to create more training data. The most common approach is data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wMQLpsF3Fq23"
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSilgb06dx7V"
   },
   "source": [
    "A convolutional neural network that can robustly classify objects even if its placed in different orientations is said to have the property called invariance. More specifically, a CNN can be invariant to translation, viewpoint, size or illumination (or a combination of the above). However, in order to achieve this we need data with sufficient variation.\n",
    "![](https://github.com/fordanic/cmiv-ai-course/blob/master/notebooks/figures/data_augmentation.png?raw=1)\n",
    "This essentially is the premise of data augmentation. In the real world scenario, we may have a dataset of images taken in a limited set of conditions. But, our target application may exist in a variety of conditions, such as different orientation, location, scale, brightness etc. We account for these situations by training our neural network with additional synthetically modified data, taking into account these different variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AzAkxZ8gdx7W"
   },
   "source": [
    "___\n",
    "## Exercise\n",
    "What are the variations that would be relevant to consider in a context of training an image classifier for radiology respectively pathology?\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ob5Q8VrPIYd4"
   },
   "source": [
    "In the following, we'll make use of the class `ImageDataGenerator` in Keras to construct additional training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hgco7q4ndx7Z"
   },
   "source": [
    "First we run an example of offline data augmentation, i.e.we create additional data prior to running the training. In this case, we only create 20 new versions from the first image patch among our training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDAMze54IlKJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "if os.path.exists(\"preview\"):\n",
    "    shutil.rmtree(\"preview\")\n",
    "os.mkdir(\"preview\")\n",
    "\n",
    "# The class ImageDataGenerator is used to create additional data\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "x = X_train[0,:,:,:]\n",
    "x = np.transpose(x) # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "x = np.transpose(x)\n",
    "print(x.shape)\n",
    "\n",
    "# The .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(X_train[0:1,:,:,:], batch_size=1, \n",
    "                          save_to_dir='preview', save_prefix='aug', save_format='png'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fq7witTWdx7f"
   },
   "source": [
    "Next, we can look at the data that we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S14gabpMMGir"
   },
   "outputs": [],
   "source": [
    "aug_filenames = glob.glob(os.path.join(\"preview\", \"*.png\"))\n",
    "\n",
    "aug_images = [matplotlib.image.imread(fname) for fname in aug_filenames]\n",
    "\n",
    "X_aug = np.vstack([np.array(aug_images, dtype=np.float32)])\n",
    "y_aug = np.array([1]*len(aug_images), dtype=np.int32)\n",
    "\n",
    "# Plot example data\n",
    "print(\"Example of augmented image samples\")\n",
    "plot_patches(X_aug, y_aug, to_plot=20)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AX6eeAahdx7l"
   },
   "source": [
    "However, for the actual training we will instead use oneline data augmentation, i.e. additional images will be created on the fly as we run the training. To do this we will make use of a data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KI-4DSYNcxk3"
   },
   "outputs": [],
   "source": [
    "# Define CNN model to use\n",
    "def build_conv_model():\n",
    "    # Images are 3 channel and 64x64\n",
    "    input = Input(shape=(64, 64, 3))\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(input)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(2)(x)\n",
    "    return Model(input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgqvqkgRtpbO"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "(X_train, y_train), (X_val, y_val) = load_data(\"epi/samples\", \"train\")\n",
    "(X_test, y_test) = load_data(\"epi/samples\", \"test\", apply_train_test_split=False)\n",
    "\n",
    "# Plot example data\n",
    "print(\"Example patches of epithelium and stroma\")\n",
    "plot_patches(X_train, y_train, to_plot=10)\n",
    "\n",
    "# Convert to expected format\n",
    "X_train, y_train = to_tensors(X_train, y_train)\n",
    "X_val, y_val = to_tensors(X_val, y_val)\n",
    "X_test, y_test = to_tensors(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uR6KDeuetsb3"
   },
   "outputs": [],
   "source": [
    "# Create a data generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KI-4DSYNcxk2"
   },
   "outputs": [],
   "source": [
    "# Run training\n",
    "with get_device():\n",
    "    model = build_conv_model()\n",
    "\n",
    "    optimizer = Adam()\n",
    "    model.compile(optimizer=optimizer, loss = crossentropy_logits, metrics=['accuracy'])\n",
    "\n",
    "    n_train = -1\n",
    "    \n",
    "    # Fits the model on batches with real-time data augmentation:\n",
    "    logs= model.fit_generator(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                              steps_per_epoch=len(X_train) / 8, epochs=25,\n",
    "                              validation_data=(X_val, y_val), \n",
    "                              verbose=0,\n",
    "                              callbacks=[LogCallback()])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHGGvrAftvDx"
   },
   "outputs": [],
   "source": [
    "# Display training curves \n",
    "plt.plot(logs.history['acc'])\n",
    "plt.plot(logs.history['val_acc'])\n",
    "plt.show()\n",
    "\n",
    "# Predict on test data\n",
    "with get_device():\n",
    "    y_proba_test = model.predict(X_test)\n",
    "\n",
    "y_pred_test = np.argmax(y_proba_test, axis=-1)\n",
    "y_true = np.argmax(y_test, axis=-1)\n",
    "errors = y_pred_test != y_true\n",
    "\n",
    "# Compute the accuracy    \n",
    "print(\"Test accuracy: {}\".format(1.0-np.mean(errors)))\n",
    "\n",
    "# Plot the first examples\n",
    "print(\"Some predicted examples\")\n",
    "to_evaluate = 15\n",
    "X_eval = X_test[:to_evaluate]    \n",
    "y_eval = y_pred_test[:to_evaluate]\n",
    "plot_patches(X_eval, y_eval, y_true=y_true[:to_evaluate])\n",
    "\n",
    "# Plot the first error examples\n",
    "print(\"Some false predictions\")\n",
    "X_eval = X_test[np.where(errors)][:to_evaluate]\n",
    "y_eval = y_pred_test[np.where(errors)][:to_evaluate]\n",
    "plot_patches(X_eval, y_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lAJFhwhedx7x"
   },
   "source": [
    "___\n",
    "## Exercise\n",
    "Explore to see if you can achieve the same results by using data augmentation as you can if you would increase the number of image patches sampled from each of image.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "08 - Deep Learning and Medical Imaging - Digital Pathology.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
